{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of features used in the regression\n",
    "window_size = 10\n",
    "# lstm_num_timesteps\n",
    "lstm_num_timesteps = 10\n",
    "# whether to use LSTM or MLP\n",
    "use_LSTM = False\n",
    "# lstm_num_features\n",
    "lstm_num_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "#df_train = pd.read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "df_train = pd.read_csv('108_7_3.train.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "ts_train = df_train.values\n",
    "df_test = pd.read_csv('108_7_3.test.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "ts_test = df_test.values\n",
    "ts_all = np.append(ts_train, ts_test).reshape(-1,1)\n",
    "len_overall = len(ts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing\n",
    "ts_train = np.arange(1,101).reshape(-1,1)  \n",
    "ts_test = np.arange(101,121).reshape(-1,1)\n",
    "window_size = 5\n",
    "ts_all = np.append(ts_train, ts_test).reshape(-1,1)\n",
    "len_overall = len(ts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  5],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [  8],\n",
       "       [  9],\n",
       "       [ 10],\n",
       "       [ 11],\n",
       "       [ 12],\n",
       "       [ 13],\n",
       "       [ 14],\n",
       "       [ 15],\n",
       "       [ 16],\n",
       "       [ 17],\n",
       "       [ 18],\n",
       "       [ 19],\n",
       "       [ 20],\n",
       "       [ 21],\n",
       "       [ 22],\n",
       "       [ 23],\n",
       "       [ 24],\n",
       "       [ 25],\n",
       "       [ 26],\n",
       "       [ 27],\n",
       "       [ 28],\n",
       "       [ 29],\n",
       "       [ 30],\n",
       "       [ 31],\n",
       "       [ 32],\n",
       "       [ 33],\n",
       "       [ 34],\n",
       "       [ 35],\n",
       "       [ 36],\n",
       "       [ 37],\n",
       "       [ 38],\n",
       "       [ 39],\n",
       "       [ 40],\n",
       "       [ 41],\n",
       "       [ 42],\n",
       "       [ 43],\n",
       "       [ 44],\n",
       "       [ 45],\n",
       "       [ 46],\n",
       "       [ 47],\n",
       "       [ 48],\n",
       "       [ 49],\n",
       "       [ 50],\n",
       "       [ 51],\n",
       "       [ 52],\n",
       "       [ 53],\n",
       "       [ 54],\n",
       "       [ 55],\n",
       "       [ 56],\n",
       "       [ 57],\n",
       "       [ 58],\n",
       "       [ 59],\n",
       "       [ 60],\n",
       "       [ 61],\n",
       "       [ 62],\n",
       "       [ 63],\n",
       "       [ 64],\n",
       "       [ 65],\n",
       "       [ 66],\n",
       "       [ 67],\n",
       "       [ 68],\n",
       "       [ 69],\n",
       "       [ 70],\n",
       "       [ 71],\n",
       "       [ 72],\n",
       "       [ 73],\n",
       "       [ 74],\n",
       "       [ 75],\n",
       "       [ 76],\n",
       "       [ 77],\n",
       "       [ 78],\n",
       "       [ 79],\n",
       "       [ 80],\n",
       "       [ 81],\n",
       "       [ 82],\n",
       "       [ 83],\n",
       "       [ 84],\n",
       "       [ 85],\n",
       "       [ 86],\n",
       "       [ 87],\n",
       "       [ 88],\n",
       "       [ 89],\n",
       "       [ 90],\n",
       "       [ 91],\n",
       "       [ 92],\n",
       "       [ 93],\n",
       "       [ 94],\n",
       "       [ 95],\n",
       "       [ 96],\n",
       "       [ 97],\n",
       "       [ 98],\n",
       "       [ 99],\n",
       "       [100],\n",
       "       [101],\n",
       "       [102],\n",
       "       [103],\n",
       "       [104],\n",
       "       [105],\n",
       "       [106],\n",
       "       [107],\n",
       "       [108],\n",
       "       [109],\n",
       "       [110],\n",
       "       [111],\n",
       "       [112],\n",
       "       [113],\n",
       "       [114],\n",
       "       [115],\n",
       "       [116],\n",
       "       [117],\n",
       "       [118],\n",
       "       [119],\n",
       "       [120]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1), (20, 1))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train.shape, ts_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10],\n",
       "       [11]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101],\n",
       "       [102],\n",
       "       [103],\n",
       "       [104],\n",
       "       [105],\n",
       "       [106],\n",
       "       [107],\n",
       "       [108],\n",
       "       [109],\n",
       "       [110],\n",
       "       [111]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_test[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#ts = scaler.fit_transform(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "#train_size = int(len(ts) * 0.67)\n",
    "#test_size = len(ts) - train_size\n",
    "#ts_train, ts_test = ts[0:train_size,:], ts[train_size:len(ts),:]\n",
    "#print(len(ts_train), len(ts_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + window_size, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95, 5), (15, 5), (95,), (15,))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = create_dataset(ts_train, window_size)\n",
    "X_test, y_test = create_dataset(ts_test, window_size)\n",
    "# the train and test matrices end up shorter than the respective timeseries by window_size + 1!\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 2,  3,  4,  5,  6],\n",
       "       [ 3,  4,  5,  6,  7],\n",
       "       [ 4,  5,  6,  7,  8],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [ 7,  8,  9, 10, 11],\n",
       "       [ 8,  9, 10, 11, 12],\n",
       "       [ 9, 10, 11, 12, 13],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [11, 12, 13, 14, 15],\n",
       "       [12, 13, 14, 15, 16],\n",
       "       [13, 14, 15, 16, 17],\n",
       "       [14, 15, 16, 17, 18],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [16, 17, 18, 19, 20],\n",
       "       [17, 18, 19, 20, 21],\n",
       "       [18, 19, 20, 21, 22],\n",
       "       [19, 20, 21, 22, 23],\n",
       "       [20, 21, 22, 23, 24],\n",
       "       [21, 22, 23, 24, 25],\n",
       "       [22, 23, 24, 25, 26],\n",
       "       [23, 24, 25, 26, 27],\n",
       "       [24, 25, 26, 27, 28],\n",
       "       [25, 26, 27, 28, 29],\n",
       "       [26, 27, 28, 29, 30],\n",
       "       [27, 28, 29, 30, 31],\n",
       "       [28, 29, 30, 31, 32],\n",
       "       [29, 30, 31, 32, 33],\n",
       "       [30, 31, 32, 33, 34],\n",
       "       [31, 32, 33, 34, 35],\n",
       "       [32, 33, 34, 35, 36],\n",
       "       [33, 34, 35, 36, 37],\n",
       "       [34, 35, 36, 37, 38],\n",
       "       [35, 36, 37, 38, 39],\n",
       "       [36, 37, 38, 39, 40],\n",
       "       [37, 38, 39, 40, 41],\n",
       "       [38, 39, 40, 41, 42],\n",
       "       [39, 40, 41, 42, 43],\n",
       "       [40, 41, 42, 43, 44],\n",
       "       [41, 42, 43, 44, 45],\n",
       "       [42, 43, 44, 45, 46],\n",
       "       [43, 44, 45, 46, 47],\n",
       "       [44, 45, 46, 47, 48],\n",
       "       [45, 46, 47, 48, 49],\n",
       "       [46, 47, 48, 49, 50],\n",
       "       [47, 48, 49, 50, 51],\n",
       "       [48, 49, 50, 51, 52],\n",
       "       [49, 50, 51, 52, 53],\n",
       "       [50, 51, 52, 53, 54],\n",
       "       [51, 52, 53, 54, 55],\n",
       "       [52, 53, 54, 55, 56],\n",
       "       [53, 54, 55, 56, 57],\n",
       "       [54, 55, 56, 57, 58],\n",
       "       [55, 56, 57, 58, 59],\n",
       "       [56, 57, 58, 59, 60],\n",
       "       [57, 58, 59, 60, 61],\n",
       "       [58, 59, 60, 61, 62],\n",
       "       [59, 60, 61, 62, 63],\n",
       "       [60, 61, 62, 63, 64],\n",
       "       [61, 62, 63, 64, 65],\n",
       "       [62, 63, 64, 65, 66],\n",
       "       [63, 64, 65, 66, 67],\n",
       "       [64, 65, 66, 67, 68],\n",
       "       [65, 66, 67, 68, 69],\n",
       "       [66, 67, 68, 69, 70],\n",
       "       [67, 68, 69, 70, 71],\n",
       "       [68, 69, 70, 71, 72],\n",
       "       [69, 70, 71, 72, 73],\n",
       "       [70, 71, 72, 73, 74],\n",
       "       [71, 72, 73, 74, 75],\n",
       "       [72, 73, 74, 75, 76],\n",
       "       [73, 74, 75, 76, 77],\n",
       "       [74, 75, 76, 77, 78],\n",
       "       [75, 76, 77, 78, 79],\n",
       "       [76, 77, 78, 79, 80],\n",
       "       [77, 78, 79, 80, 81],\n",
       "       [78, 79, 80, 81, 82],\n",
       "       [79, 80, 81, 82, 83],\n",
       "       [80, 81, 82, 83, 84],\n",
       "       [81, 82, 83, 84, 85],\n",
       "       [82, 83, 84, 85, 86],\n",
       "       [83, 84, 85, 86, 87],\n",
       "       [84, 85, 86, 87, 88],\n",
       "       [85, 86, 87, 88, 89],\n",
       "       [86, 87, 88, 89, 90],\n",
       "       [87, 88, 89, 90, 91],\n",
       "       [88, 89, 90, 91, 92],\n",
       "       [89, 90, 91, 92, 93],\n",
       "       [90, 91, 92, 93, 94],\n",
       "       [91, 92, 93, 94, 95],\n",
       "       [92, 93, 94, 95, 96],\n",
       "       [93, 94, 95, 96, 97],\n",
       "       [94, 95, 96, 97, 98],\n",
       "       [95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,\n",
       "        19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
       "        32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,\n",
       "        45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "        58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "        71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
       "        97,  98,  99, 100])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 102, 103, 104, 105],\n",
       "       [102, 103, 104, 105, 106],\n",
       "       [103, 104, 105, 106, 107],\n",
       "       [104, 105, 106, 107, 108],\n",
       "       [105, 106, 107, 108, 109],\n",
       "       [106, 107, 108, 109, 110],\n",
       "       [107, 108, 109, 110, 111],\n",
       "       [108, 109, 110, 111, 112],\n",
       "       [109, 110, 111, 112, 113],\n",
       "       [110, 111, 112, 113, 114],\n",
       "       [111, 112, 113, 114, 115],\n",
       "       [112, 113, 114, 115, 116],\n",
       "       [113, 114, 115, 116, 117],\n",
       "       [114, 115, 116, 117, 118],\n",
       "       [115, 116, 117, 118, 119]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_LSTM:\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "95/95 [==============================] - 0s - loss: 1903.3793     \n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 0s - loss: 313.0043     \n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 0s - loss: 11.6479     \n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 0s - loss: 3.6512     \n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 0s - loss: 3.6223     \n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 0s - loss: 3.5881     \n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 0s - loss: 3.5611     \n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 0s - loss: 3.5458     \n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 0s - loss: 3.4458     \n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 0s - loss: 3.4961     \n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 0s - loss: 3.4285     \n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 0s - loss: 3.3570     \n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 0s - loss: 3.3473     \n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 0s - loss: 3.2743     \n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 0s - loss: 3.2149     \n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 0s - loss: 3.1430     \n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 0s - loss: 3.1281     \n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 0s - loss: 3.0606     - ETA: 0s - lo - ETA: 0s - loss: 3.050\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 0s - loss: 2.9640     \n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 0s - loss: 2.9304     \n",
      "Epoch 21/100\n",
      "95/95 [==============================] - 0s - loss: 2.8873     - ETA: 0s\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - 0s - loss: 2.8940     \n",
      "Epoch 23/100\n",
      "95/95 [==============================] - 0s - loss: 2.7046     \n",
      "Epoch 24/100\n",
      "95/95 [==============================] - 0s - loss: 2.7453     \n",
      "Epoch 25/100\n",
      "95/95 [==============================] - 0s - loss: 2.6845     \n",
      "Epoch 26/100\n",
      "95/95 [==============================] - 0s - loss: 2.5484     \n",
      "Epoch 27/100\n",
      "95/95 [==============================] - 0s - loss: 2.5289     - ETA: 0s - loss: 2.482\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - 0s - loss: 2.4040     - ETA: 0s - loss\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - 0s - loss: 2.3396     - ETA: 0s - lo\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - 0s - loss: 2.2556     \n",
      "Epoch 31/100\n",
      "95/95 [==============================] - 0s - loss: 2.1547     \n",
      "Epoch 32/100\n",
      "95/95 [==============================] - 0s - loss: 2.0291     \n",
      "Epoch 33/100\n",
      "95/95 [==============================] - 0s - loss: 1.9920     \n",
      "Epoch 34/100\n",
      "95/95 [==============================] - 0s - loss: 1.8845     \n",
      "Epoch 35/100\n",
      "95/95 [==============================] - 0s - loss: 1.9167     \n",
      "Epoch 36/100\n",
      "95/95 [==============================] - 0s - loss: 1.7666     \n",
      "Epoch 37/100\n",
      "95/95 [==============================] - 0s - loss: 1.7032     \n",
      "Epoch 38/100\n",
      "95/95 [==============================] - 0s - loss: 1.5950     \n",
      "Epoch 39/100\n",
      "95/95 [==============================] - 0s - loss: 1.6104     \n",
      "Epoch 40/100\n",
      "95/95 [==============================] - 0s - loss: 1.4728     \n",
      "Epoch 41/100\n",
      "95/95 [==============================] - 0s - loss: 1.5377     \n",
      "Epoch 42/100\n",
      "95/95 [==============================] - 0s - loss: 1.4131     \n",
      "Epoch 43/100\n",
      "95/95 [==============================] - 0s - loss: 1.2270     \n",
      "Epoch 44/100\n",
      "95/95 [==============================] - 0s - loss: 1.2097     \n",
      "Epoch 45/100\n",
      "95/95 [==============================] - 0s - loss: 1.0880     \n",
      "Epoch 46/100\n",
      "95/95 [==============================] - 0s - loss: 1.0665     \n",
      "Epoch 47/100\n",
      "95/95 [==============================] - 0s - loss: 0.9818     \n",
      "Epoch 48/100\n",
      "95/95 [==============================] - 0s - loss: 0.8969     \n",
      "Epoch 49/100\n",
      "95/95 [==============================] - 0s - loss: 0.8746     \n",
      "Epoch 50/100\n",
      "95/95 [==============================] - 0s - loss: 0.7936     \n",
      "Epoch 51/100\n",
      "95/95 [==============================] - 0s - loss: 0.7726     \n",
      "Epoch 52/100\n",
      "95/95 [==============================] - 0s - loss: 0.8190     \n",
      "Epoch 53/100\n",
      "95/95 [==============================] - 0s - loss: 0.6210     \n",
      "Epoch 54/100\n",
      "95/95 [==============================] - 0s - loss: 0.5893     - ETA: 0s - l\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - 0s - loss: 0.5428     \n",
      "Epoch 56/100\n",
      "95/95 [==============================] - 0s - loss: 0.5269     \n",
      "Epoch 57/100\n",
      "95/95 [==============================] - 0s - loss: 0.4888     \n",
      "Epoch 58/100\n",
      "95/95 [==============================] - 0s - loss: 0.4948     \n",
      "Epoch 59/100\n",
      "95/95 [==============================] - 0s - loss: 0.3820     \n",
      "Epoch 60/100\n",
      "95/95 [==============================] - 0s - loss: 0.3319     \n",
      "Epoch 61/100\n",
      "95/95 [==============================] - 0s - loss: 0.3507     - ETA: \n",
      "Epoch 62/100\n",
      "95/95 [==============================] - 0s - loss: 0.2681     \n",
      "Epoch 63/100\n",
      "95/95 [==============================] - 0s - loss: 0.2570     \n",
      "Epoch 64/100\n",
      "95/95 [==============================] - 0s - loss: 0.2594     \n",
      "Epoch 65/100\n",
      "95/95 [==============================] - 0s - loss: 0.1837     - ETA: 0s - loss: 0\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - 0s - loss: 0.1884     \n",
      "Epoch 67/100\n",
      "95/95 [==============================] - 0s - loss: 0.1328     \n",
      "Epoch 68/100\n",
      "95/95 [==============================] - 0s - loss: 0.1236     \n",
      "Epoch 69/100\n",
      "95/95 [==============================] - 0s - loss: 0.1201     \n",
      "Epoch 70/100\n",
      "95/95 [==============================] - 0s - loss: 0.1092     \n",
      "Epoch 71/100\n",
      "95/95 [==============================] - 0s - loss: 0.0862     \n",
      "Epoch 72/100\n",
      "95/95 [==============================] - 0s - loss: 0.0744     \n",
      "Epoch 73/100\n",
      "95/95 [==============================] - 0s - loss: 0.0635     \n",
      "Epoch 74/100\n",
      "95/95 [==============================] - 0s - loss: 0.0459     \n",
      "Epoch 75/100\n",
      "95/95 [==============================] - 0s - loss: 0.0375     \n",
      "Epoch 76/100\n",
      "95/95 [==============================] - 0s - loss: 0.0370     \n",
      "Epoch 77/100\n",
      "95/95 [==============================] - 0s - loss: 0.0289     \n",
      "Epoch 78/100\n",
      "95/95 [==============================] - 0s - loss: 0.0224     \n",
      "Epoch 79/100\n",
      "95/95 [==============================] - 0s - loss: 0.0277     \n",
      "Epoch 80/100\n",
      "95/95 [==============================] - 0s - loss: 0.0167     \n",
      "Epoch 81/100\n",
      "95/95 [==============================] - 0s - loss: 0.0107     \n",
      "Epoch 82/100\n",
      "95/95 [==============================] - 0s - loss: 0.0078     - ETA: 0\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - 0s - loss: 0.0059     \n",
      "Epoch 84/100\n",
      "95/95 [==============================] - 0s - loss: 0.0050     \n",
      "Epoch 85/100\n",
      "95/95 [==============================] - 0s - loss: 0.0043     \n",
      "Epoch 86/100\n",
      "95/95 [==============================] - 0s - loss: 0.0039     \n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 0.001 - 0s - loss: 0.0017     \n",
      "Epoch 88/100\n",
      "95/95 [==============================] - 0s - loss: 0.0051     \n",
      "Epoch 89/100\n",
      "95/95 [==============================] - 0s - loss: 0.0027     \n",
      "Epoch 90/100\n",
      "95/95 [==============================] - 0s - loss: 5.7341e-04     \n",
      "Epoch 91/100\n",
      "95/95 [==============================] - 0s - loss: 5.8481e-04     \n",
      "Epoch 92/100\n",
      "95/95 [==============================] - 0s - loss: 4.5740e-04     \n",
      "Epoch 93/100\n",
      "95/95 [==============================] - 0s - loss: 3.0312e-04     \n",
      "Epoch 94/100\n",
      "95/95 [==============================] - 0s - loss: 1.7325e-04     \n",
      "Epoch 95/100\n",
      "95/95 [==============================] - 0s - loss: 1.9363e-04     \n",
      "Epoch 96/100\n",
      "95/95 [==============================] - 0s - loss: 7.1068e-05     \n",
      "Epoch 97/100\n",
      "95/95 [==============================] - 0s - loss: 2.1942e-05     \n",
      "Epoch 98/100\n",
      "95/95 [==============================] - 0s - loss: 1.5319e-05     \n",
      "Epoch 99/100\n",
      "95/95 [==============================] - 0s - loss: 2.7794e-05     \n",
      "Epoch 100/100\n",
      "95/95 [==============================] - 0s - loss: 1.8771e-05     - ETA: 0s - loss:\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if use_LSTM:\n",
    "    model.add(LSTM(4, input_dim=lstm_num_features))\n",
    "else:\n",
    "    model.add(Dense(8, input_dim=window_size, activation='relu'))\n",
    "    \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "if use_LSTM:\n",
    "    model.fit(X_train, y_train, nb_epoch=10, batch_size=1)\n",
    "else:\n",
    "    hist = model.fit(X_train, y_train, nb_epoch=100, batch_size=1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 1,\n",
       " 'do_validation': False,\n",
       " 'metrics': ['loss'],\n",
       " 'nb_epoch': 100,\n",
       " 'nb_sample': 95,\n",
       " 'verbose': 1}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['loss'], [])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names, model.metrics_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00012289897131267935"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       " array([  5.9979248 ,   6.99804735,   7.9981699 ,   8.99829292,\n",
       "          9.99841595,  10.99853897,  11.99866199,  12.99878407,\n",
       "         13.99890804,  14.99903011], dtype=float32))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10],pred_train[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([106, 107, 108, 109, 110, 111, 112, 113, 114, 115]),\n",
       " array([ 106.01021576,  107.0103302 ,  108.0104599 ,  109.0105896 ,\n",
       "         110.01070404,  111.01082611,  112.01095581,  113.01107025,\n",
       "         114.01119232,  115.01132965], dtype=float32))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10],pred_test[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.01 RMSE\n",
      "Test Score: 0.01 RMSE\n"
     ]
    }
   ],
   "source": [
    "# invert predictions\n",
    "#pred_train = scaler.inverse_transform(pred_train)\n",
    "#y_train = scaler.inverse_transform([y_train])\n",
    "#pred_test = scaler.inverse_transform(pred_test)\n",
    "#y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "# calculate root mean squared error\n",
    "rsme_train = math.sqrt(mean_squared_error(y_train, pred_train[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (rsme_train))\n",
    "rsme_test = math.sqrt(mean_squared_error(y_test, pred_test[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (rsme_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 95 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 15, 15)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ts_train), len(pred_train), len(y_train))\n",
    "len(ts_test), len(pred_test), len(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [                   5],\n",
       "       [                   6],\n",
       "       [                   7],\n",
       "       [                   8],\n",
       "       [                   9],\n",
       "       [                  10],\n",
       "       [                  11],\n",
       "       [                  12],\n",
       "       [                  13],\n",
       "       [                  14],\n",
       "       [                  15],\n",
       "       [                  16],\n",
       "       [                  17],\n",
       "       [                  18],\n",
       "       [                  19],\n",
       "       [                  20],\n",
       "       [                  21],\n",
       "       [                  23],\n",
       "       [                  24],\n",
       "       [                  25],\n",
       "       [                  26],\n",
       "       [                  27],\n",
       "       [                  28],\n",
       "       [                  29],\n",
       "       [                  30],\n",
       "       [                  31],\n",
       "       [                  32],\n",
       "       [                  33],\n",
       "       [                  34],\n",
       "       [                  35],\n",
       "       [                  36],\n",
       "       [                  37],\n",
       "       [                  38],\n",
       "       [                  39],\n",
       "       [                  40],\n",
       "       [                  41],\n",
       "       [                  42],\n",
       "       [                  43],\n",
       "       [                  44],\n",
       "       [                  45],\n",
       "       [                  46],\n",
       "       [                  47],\n",
       "       [                  48],\n",
       "       [                  49],\n",
       "       [                  50],\n",
       "       [                  51],\n",
       "       [                  52],\n",
       "       [                  53],\n",
       "       [                  54],\n",
       "       [                  55],\n",
       "       [                  56],\n",
       "       [                  57],\n",
       "       [                  58],\n",
       "       [                  59],\n",
       "       [                  60],\n",
       "       [                  61],\n",
       "       [                  62],\n",
       "       [                  63],\n",
       "       [                  64],\n",
       "       [                  65],\n",
       "       [                  66],\n",
       "       [                  67],\n",
       "       [                  68],\n",
       "       [                  69],\n",
       "       [                  70],\n",
       "       [                  71],\n",
       "       [                  72],\n",
       "       [                  73],\n",
       "       [                  74],\n",
       "       [                  75],\n",
       "       [                  76],\n",
       "       [                  77],\n",
       "       [                  78],\n",
       "       [                  79],\n",
       "       [                  80],\n",
       "       [                  81],\n",
       "       [                  82],\n",
       "       [                  83],\n",
       "       [                  84],\n",
       "       [                  85],\n",
       "       [                  86],\n",
       "       [                  87],\n",
       "       [                  88],\n",
       "       [                  89],\n",
       "       [                  90],\n",
       "       [                  91],\n",
       "       [                  92],\n",
       "       [                  93],\n",
       "       [                  94],\n",
       "       [                  95],\n",
       "       [                  96],\n",
       "       [                  97],\n",
       "       [                  98],\n",
       "       [                  99],\n",
       "       [                 100],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift train predictions for plotting\n",
    "pred_train_shifted = np.empty_like(ts_all)\n",
    "print(pred_train_shifted.size)\n",
    "pred_train_shifted[:, :] = np.nan\n",
    "# train predictions start at position window_size + 1 (or window_size, if counting from 0)\n",
    "pred_train_shifted[window_size : len(pred_train) + window_size, :] = pred_train\n",
    "pred_train_shifted[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [-9223372036854775808],\n",
       "       [                 106],\n",
       "       [                 107],\n",
       "       [                 108],\n",
       "       [                 109],\n",
       "       [                 110],\n",
       "       [                 111],\n",
       "       [                 112],\n",
       "       [                 113],\n",
       "       [                 114],\n",
       "       [                 115],\n",
       "       [                 116],\n",
       "       [                 117],\n",
       "       [                 118],\n",
       "       [                 119],\n",
       "       [                 120]])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift test predictions for plotting\n",
    "pred_test_shifted = np.empty_like(ts_all)\n",
    "pred_test_shifted[:, :] = np.nan\n",
    "pred_test_shifted[len(pred_train) + (window_size * 2) : len_overall + 1, :] = pred_test\n",
    "pred_test_shifted[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEDCAYAAAA849PJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqf8HOdt/VE229mEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58f11aef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(ts_all)\n",
    "#plt.plot(pred_train_shifted)\n",
    "#plt.plot(pred_test_shifted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
