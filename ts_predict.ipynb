{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether to use LSTM or MLP\n",
    "use_LSTM = True\n",
    "\n",
    "# number of features used in the regression (for MLP)\n",
    "mlp_num_features = 10\n",
    "#\n",
    "\n",
    "# lstm_num_timesteps\n",
    "lstm_num_timesteps = 10\n",
    "# lstm_num_features\n",
    "lstm_num_features = 1\n",
    "# stateful?\n",
    "lstm_stateful = False\n",
    "# use two lstm layers?\n",
    "lstm_stack_layers = False\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "num_epochs = 1000\n",
    "num_neurons = 4\n",
    "\n",
    "# scale the dataset to values between scale_min and scale_max\n",
    "scale = True\n",
    "scale_min = -1\n",
    "scale_max = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '108_7_3.train.csv'\n",
    "df_train = pd.read_csv(filename, usecols=[1])\n",
    "ts_train = df_train.values.astype('float64')\n",
    "df_test = pd.read_csv(filename, usecols=[1])\n",
    "ts_test = df_test.values.astype('float64')\n",
    "ts_all = np.append(ts_train, ts_test).reshape(-1,1)\n",
    "len_overall = len(ts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train.shape, ts_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scale:\n",
    "    scaler = MinMaxScaler(feature_range=(scale_min, scale_max))\n",
    "    ts_train = scaler.fit_transform(ts_train)\n",
    "    ts_test = scaler.transform(ts_test)\n",
    "    scaler.data_min_, scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "#train_size = int(len(ts) * 0.67)\n",
    "#test_size = len(ts) - train_size\n",
    "#ts_train, ts_test = ts[0:train_size,:], ts[train_size:len(ts),:]\n",
    "#print(len(ts_train), len(ts_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + window_size, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windowed(ts, lag):\n",
    "    df = pd.DataFrame(ts)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df = df.drop(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_LSTM:\n",
    "    X_train, y_train = create_dataset(ts_train, lstm_num_timesteps)\n",
    "    X_test, y_test = create_dataset(ts_test, lstm_num_timesteps)\n",
    "else:\n",
    "    X_train, y_train = create_dataset(ts_train, mlp_num_features)\n",
    "    X_test, y_test = create_dataset(ts_test, mlp_num_features)\n",
    "    \n",
    "# the train and test matrices end up shorter than the respective timeseries by window_size + 1!\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_LSTM:\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if use_LSTM:\n",
    "    \n",
    "    # the last state for each sample at index i in a batch will be used as initial state\n",
    "    # for the sample of index i in the following batch\n",
    "    if lstm_stateful:\n",
    "        #\n",
    "        #\n",
    "        if lstm_stack_layers:\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                       stateful = True,\n",
    "                       return_sequences = True))\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       stateful = True))\n",
    "        # \n",
    "        else:\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                       stateful = True))\n",
    "          \n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            print('epoch: ' + str(i))\n",
    "            # shuffle must be False!\n",
    "            model.fit(X_train, y_train, nb_epoch = 1, batch_size = batch_size, shuffle = False)\n",
    "            model.reset_states()\n",
    " \n",
    "\n",
    "    # stateful == False    \n",
    "    else:        \n",
    "        \n",
    "        if lstm_stack_layers:\n",
    "            # input_dim: dimensionality of the input (alternatively, input_shape)\n",
    "            # required when using this layer as the first layer in a model\n",
    "            model.add(LSTM(num_neurons, input_dim = lstm_num_features, return_sequences = True))\n",
    "            model.add(LSTM(num_neurons))\n",
    "        # \n",
    "        else:\n",
    "            model.add(LSTM(num_neurons, input_dim = lstm_num_features))\n",
    "        \n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n",
    "        \n",
    "   \n",
    "\n",
    "# feedforward\n",
    "else:\n",
    "    \n",
    "    model.add(Dense(num_neurons, input_dim = mlp_num_features, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = np.nan\n",
    "if lstm_stateful:\n",
    "    test_loss = model.evaluate(X_test, y_test, batch_size = batch_size)\n",
    "else:\n",
    "    test_loss = model.evaluate(X_test, y_test, batch_size = X_test.shape[0])\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lstm_stateful:\n",
    "    pred_train = model.predict(X_train, batch_size = batch_size)\n",
    "    pred_test = model.predict(X_test, batch_size = batch_size)\n",
    "else:\n",
    "    pred_train = model.predict(X_train, batch_size = X_train.shape[0])\n",
    "    pred_test = model.predict(X_test, batch_size = X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scale:\n",
    "    pred_train = scaler.inverse_transform(pred_train)\n",
    "    y_train = scaler.inverse_transform(y_train.reshape(-1,1))\n",
    "    pred_test = scaler.inverse_transform(pred_test)\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10],pred_train[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10],pred_test[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "rsme_train = math.sqrt(mean_squared_error(y_train, pred_train[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (rsme_train))\n",
    "rsme_test = math.sqrt(mean_squared_error(y_test, pred_test[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (rsme_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ts_train), len(pred_train), len(y_train))\n",
    "len(ts_test), len(pred_test), len(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "window_size = lstm_num_timesteps if use_LSTM else mlp_num_features\n",
    "pred_train_shifted = np.empty_like(ts_all)\n",
    "print(pred_train_shifted.size)\n",
    "pred_train_shifted[:, :] = np.nan\n",
    "# train predictions start at position window_size + 1 (or window_size, if counting from 0)\n",
    "pred_train_shifted[window_size : len(pred_train) + window_size, :] = pred_train\n",
    "pred_train_shifted[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "window_size = lstm_num_timesteps if use_LSTM else mlp_num_features\n",
    "pred_test_shifted = np.empty_like(ts_all)\n",
    "pred_test_shifted[:, :] = np.nan\n",
    "pred_test_shifted[len(pred_train) + (window_size * 2) : len_overall + 1, :] = pred_test\n",
    "pred_test_shifted[-13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_all)\n",
    "plt.plot(pred_train_shifted)\n",
    "plt.plot(pred_test_shifted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = -100\n",
    "plot_end = -1\n",
    "plt.plot(ts_all[plot_start:plot_end])\n",
    "plt.plot(pred_train_shifted[plot_start:plot_end])\n",
    "plt.plot(pred_test_shifted[plot_start:plot_end])\n",
    "plt.savefig(filename + '_lstm_' + str(use_LSTM) + '_stateful_' + str(lstm_stateful) + '_batchsize_' + str(batch_size) + '_window_' + str(window_size) +\n",
    "            '_epochs_' + str(num_epochs) + '_2layers_' + str(lstm_stack_layers) + '.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
