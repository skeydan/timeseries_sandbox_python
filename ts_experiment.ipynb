{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributedDense\n",
    "from keras.layers import LSTM\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TBD different random seeds\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On statefulness\n",
    "\n",
    "Making a RNN stateful means that the states for the samples of each batch will be reused as initial states for the samples in the next batch.\n",
    "\n",
    "When using stateful RNNs, it is therefore assumed that:\n",
    "\n",
    "- all batches have the same number of samples\n",
    "- if X1 and X2 are successive batches of samples, then X2[i] is the follow-up sequence to X1[i], for every i.\n",
    "\n",
    "Notes that the methods predict, fit, train_on_batch, predict_classes, etc. will all update the states of the stateful layers in a model. This allows you to do not only stateful training, but also stateful prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X  # this is our input data, of shape (32, 21, 16)\n",
    "# we will feed it to our model in sequences of length 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 16), batch_size=32, stateful=True))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# we train the network to predict the 11th timestep given the first 10:\n",
    "model.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))\n",
    "\n",
    "# the state of the network has changed. We can feed the follow-up sequences:\n",
    "model.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))\n",
    "\n",
    "# let's reset the states of the LSTM layer:\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether to use LSTM or MLP\n",
    "use_LSTM = True\n",
    "\n",
    "# number of features used in the regression (for MLP)\n",
    "mlp_num_features = 10\n",
    "#\n",
    "\n",
    "# predict several timesteps at once\n",
    "lstm_predict_sequences = True\n",
    "lstm_num_predictions = 5\n",
    "\n",
    "# lstm_num_timesteps\n",
    "lstm_num_timesteps = 5\n",
    "# lstm_num_features\n",
    "lstm_num_features = 1\n",
    "# stateful?\n",
    "lstm_stateful = False\n",
    "# use two lstm layers?\n",
    "lstm_stack_layers = False\n",
    "\n",
    "# window_size\n",
    "window_size = lstm_num_timesteps if use_LSTM else mlp_num_features\n",
    "\n",
    "batch_size = 1\n",
    "num_epochs = 200\n",
    "num_neurons = 4\n",
    "\n",
    "# scale the dataset to values between scale_min and scale_max\n",
    "scale = False\n",
    "scale_min = -1\n",
    "scale_max = 1\n",
    "#scaler = MinMaxScaler(feature_range=(scale_min, scale_max))\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# various test datasets\n",
    "ts_train_lineartrend = np.arange(1,101, dtype='float64').reshape(-1,1)  \n",
    "ts_test_lineartrend_outofrange = np.arange(101,121, dtype='float64').reshape(-1,1)\n",
    "ts_test_lineartrend_withinrange = np.arange(21,41, dtype='float64').reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testname = 'linear_trend_within_range'\n",
    "ts_train = ts_train_lineartrend\n",
    "ts_test = ts_test_lineartrend_withinrange\n",
    "ts_all = np.append(ts_train, ts_test).reshape(-1,1)\n",
    "len_overall = len(ts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_all.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1), (20, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train.shape, ts_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.],\n",
       "       [  2.],\n",
       "       [  3.],\n",
       "       [  4.],\n",
       "       [  5.],\n",
       "       [  6.],\n",
       "       [  7.],\n",
       "       [  8.],\n",
       "       [  9.],\n",
       "       [ 10.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.],\n",
       "       [ 22.],\n",
       "       [ 23.],\n",
       "       [ 24.],\n",
       "       [ 25.],\n",
       "       [ 26.],\n",
       "       [ 27.],\n",
       "       [ 28.],\n",
       "       [ 29.],\n",
       "       [ 30.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scale:\n",
    "    ts_train = scaler.fit_transform(ts_train)\n",
    "    ts_test = scaler.transform(ts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.],\n",
       "       [  2.],\n",
       "       [  3.],\n",
       "       [  4.],\n",
       "       [  5.],\n",
       "       [  6.],\n",
       "       [  7.],\n",
       "       [  8.],\n",
       "       [  9.],\n",
       "       [ 10.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.],\n",
       "       [ 22.],\n",
       "       [ 23.],\n",
       "       [ 24.],\n",
       "       [ 25.],\n",
       "       [ 26.],\n",
       "       [ 27.],\n",
       "       [ 28.],\n",
       "       [ 29.],\n",
       "       [ 30.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, window_size):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + window_size, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95, 5), (15, 5), (95,), (15,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_LSTM:\n",
    "    X_train, y_train = create_dataset(ts_train, lstm_num_timesteps)\n",
    "    X_test, y_test = create_dataset(ts_test, lstm_num_timesteps)\n",
    "else:\n",
    "    X_train, y_train = create_dataset(ts_train, mlp_num_features)\n",
    "    X_test, y_test = create_dataset(ts_test, mlp_num_features)\n",
    "    \n",
    "# the train and test matrices end up shorter than the respective timeseries by window_size + 1!\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.],\n",
       "       [ 2.,  3.,  4.,  5.,  6.],\n",
       "       [ 3.,  4.,  5.,  6.,  7.],\n",
       "       [ 4.,  5.,  6.,  7.,  8.],\n",
       "       [ 5.,  6.,  7.,  8.,  9.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.,   7.,   8.,   9.,  10.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.,  22.,  23.,  24.,  25.],\n",
       "       [ 22.,  23.,  24.,  25.,  26.],\n",
       "       [ 23.,  24.,  25.,  26.,  27.],\n",
       "       [ 24.,  25.,  26.,  27.,  28.],\n",
       "       [ 25.,  26.,  27.,  28.,  29.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26.,  27.,  28.,  29.,  30.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_LSTM:\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], lstm_num_timesteps, lstm_num_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], lstm_num_timesteps, lstm_num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/keras/layers/core.py:1112: UserWarning: TimeDistributedDense is deprecated, please use TimeDistributed(Dense(...)) instead.\n",
      "  warnings.warn('TimeDistributedDense is deprecated, '\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error when checking model target: expected timedistributeddense_3 to have 3 dimensions, but got array with shape (95, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-72e3e06b5b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributedDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_num_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    981\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m    984\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m    985\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     98\u001b[0m                                 \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                                 \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                                 str(array.shape))\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model target: expected timedistributeddense_3 to have 3 dimensions, but got array with shape (95, 1)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "if use_LSTM:\n",
    "    \n",
    "    # the last state for each sample at index i in a batch will be used as initial state\n",
    "    # for the sample of index i in the following batch\n",
    "    if lstm_stateful:\n",
    "        #\n",
    "        #\n",
    "        if lstm_stack_layers:\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                       stateful = True,\n",
    "                       return_sequences = True))\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       stateful = True))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            \n",
    "        # \n",
    "        elif lstm_predict_sequences:\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                       stateful = True,\n",
    "                       return_sequences = True))\n",
    "            model.add(TimeDistributedDense(lstm_num_predictions), activation = 'linear')  \n",
    "            model.add(Activation(\"linear\"))  \n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            \n",
    "        #    \n",
    "        else:\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                       stateful = True))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            print('epoch: ' + str(i))\n",
    "            # shuffle must be False!\n",
    "            model.fit(X_train, y_train, nb_epoch = 1, batch_size = batch_size, shuffle = False)\n",
    "            model.reset_states()\n",
    " \n",
    "\n",
    "    # stateful == False    \n",
    "    else:        \n",
    "        \n",
    "        if lstm_stack_layers:\n",
    "            # input_dim: dimensionality of the input (alternatively, input_shape)\n",
    "            # required when using this layer as the first layer in a model\n",
    "            model.add(LSTM(num_neurons, input_dim = lstm_num_features, return_sequences = True))\n",
    "            model.add(LSTM(num_neurons))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n",
    "        # \n",
    "        # \n",
    "        elif lstm_predict_sequences:\n",
    "            model.add(LSTM(num_neurons,\n",
    "                       batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]),\n",
    "                       stateful = True,\n",
    "                       return_sequences = True))\n",
    "            model.add(TimeDistributedDense(lstm_num_predictions))  \n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n",
    "            \n",
    "        else:\n",
    "            model.add(LSTM(num_neurons, input_dim = lstm_num_features))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n",
    "        \n",
    "   \n",
    "\n",
    "# feedforward\n",
    "else:\n",
    "    \n",
    "    model.add(Dense(num_neurons, input_dim = mlp_num_features, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, nb_epoch = num_epochs, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = np.nan\n",
    "if lstm_stateful:\n",
    "    test_loss = model.evaluate(X_test, y_test, batch_size = batch_size)\n",
    "else:\n",
    "    test_loss = model.evaluate(X_test, y_test, batch_size = X_test.shape[0])\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if lstm_stateful:\n",
    "    model.reset_states()\n",
    "    pred_train = model.predict(X_train, batch_size = batch_size)\n",
    "    model.reset_states()\n",
    "    pred_test = model.predict(X_test, batch_size = batch_size)\n",
    "else:\n",
    "    pred_train1 = model.predict(X_train, batch_size = X_train.shape[0])\n",
    "    pred_test1 = model.predict(X_test, batch_size = X_test.shape[0])\n",
    "    pred_train2 = model.predict(X_train, batch_size = batch_size)\n",
    "    pred_test2 = model.predict(X_test, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not lstm_stateful:\n",
    "#    print(np.round(pred_test1) == np.round(pred_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not lstm_stateful:\n",
    "    pred_test = pred_test1\n",
    "    pred_train = pred_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_test:\n",
    "    if lstm_stateful:\n",
    "        model.reset_states()\n",
    "    #print(i)\n",
    "    r = i.reshape(1, len(i), 1)\n",
    "    #print(i.shape), print(r.shape)\n",
    "    print(model.predict(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dependent_predictions(model, data, prediction_window):\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_window)):\n",
    "        print('Calculating predictions starting from: {}'.format(i))\n",
    "        curr_frame = data[i*prediction_window]\n",
    "        predicted = []\n",
    "        for j in range(prediction_window):\n",
    "            #print('Calculating single prediction: {}'.format(j))\n",
    "            #print(curr_frame)\n",
    "            pred = model.predict(curr_frame[np.newaxis,:,:])[0,0]\n",
    "            #pred = model.predict(curr_frame.reshape(1, len(curr_frame), 1)) # same\n",
    "            #print(pred)\n",
    "            predicted.append(pred)\n",
    "            curr_frame = curr_frame[1:] \n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_window = 5 \n",
    "\n",
    "prediction_seqs_train = calc_dependent_predictions(model, X_train, prediction_window)\n",
    "prediction_seqs_test = calc_dependent_predictions(model, X_test, prediction_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_seqs_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_seqs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scale:\n",
    "    pred_train = scaler.inverse_transform(pred_train)\n",
    "    y_train = scaler.inverse_transform(y_train.reshape(-1,1))\n",
    "    pred_test = scaler.inverse_transform(pred_test)\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10],pred_train[:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:],pred_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "rsme_train = math.sqrt(mean_squared_error(y_train, pred_train[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (rsme_train))\n",
    "rsme_test = math.sqrt(mean_squared_error(y_test, pred_test[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (rsme_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ts_train), len(pred_train), len(y_train))\n",
    "len(ts_test), len(pred_test), len(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "pred_train_shifted = np.empty_like(ts_all)\n",
    "print(pred_train_shifted.size)\n",
    "pred_train_shifted[:, :] = np.nan\n",
    "# train predictions start at position window_size + 1 (or window_size, if counting from 0)\n",
    "pred_train_shifted[window_size : len(pred_train) + window_size, :] = pred_train\n",
    "pred_train_shifted[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "window_size = lstm_num_timesteps if use_LSTM else mlp_num_features\n",
    "pred_test_shifted = np.empty_like(ts_all)\n",
    "pred_test_shifted[:, :] = np.nan\n",
    "pred_test_shifted[len(pred_train) + (window_size * 2) : len_overall + 1, :] = pred_test\n",
    "pred_test_shifted[-13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_all)\n",
    "plt.plot(pred_train_shifted)\n",
    "plt.plot(pred_test_shifted)\n",
    "plt.savefig(testname + '_lstm_' + str(use_LSTM) + '_stateful_' + str(lstm_stateful) + '_window_' + str(window_size) +\n",
    "            '_epochs_' + str(num_epochs) + '_2layers_' + str(lstm_stack_layers) + '_scale_' + str(scale) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_start = -30\n",
    "plot_end = -1\n",
    "plt.plot(ts_all[plot_start:plot_end])\n",
    "plt.plot(pred_train_shifted[plot_start:plot_end])\n",
    "plt.plot(pred_test_shifted[plot_start:plot_end])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(predicted_data, true_data):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_results(pred_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results_multiple(predicted_data, true_data, prediction_window):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_window)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_multiple(prediction_seqs_train, y_test, prediction_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_results_multiple(prediction_seqs_test, y_test, prediction_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seq2seq\n",
    "# predict and append prediction to existing values\n",
    "# TimeDistributedDense after return_sequences True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://groups.google.com/forum/#!topic/keras-users/9GsDwkSdqBg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/fchollet/keras/issues/1029#issuecomment-160845826\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import TimeDistributedDense, Activation, Dropout  \n",
    "from keras.layers.recurrent import GRU\n",
    "import numpy as np\n",
    "\n",
    "def _load_data(data, steps = 40):  \n",
    "    docX, docY = [], []\n",
    "    for i in range(0, data.shape[0]/steps-1):\n",
    "        docX.append(data[i*steps:(i+1)*steps,:])\n",
    "        docY.append(data[(i*steps+1):((i+1)*steps+1),:])\n",
    "    return np.array(docX), np.array(docY)\n",
    "\n",
    "def train_test_split(data, test_size=0.15):  \n",
    "    #    This just splits data to training and testing parts\n",
    "    X,Y = _load_data(data)\n",
    "    ntrn = round(X.shape[0] * (1 - test_size))\n",
    "    perms = np.random.permutation(X.shape[0])\n",
    "    X_train, Y_train = X.take(perms[0:ntrn],axis=0), Y.take(perms[0:ntrn],axis=0)\n",
    "    X_test, Y_test = X.take(perms[ntrn:],axis=0),Y.take(perms[ntrn:],axis=0)\n",
    "    return (X_train, Y_train), (X_test, Y_test) \n",
    "\n",
    "np.random.seed(0)  # For reproducability\n",
    "data = np.genfromtxt('closingAdjLog.csv', delimiter=',')  # data = a TxN matrix\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(np.flipud(data))  # retrieve data\n",
    "print \"Data loaded.\"\n",
    "\n",
    "in_out_neurons = 20  \n",
    "hidden_neurons = 200\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(GRU(hidden_neurons, input_dim=in_out_neurons, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributedDense(in_out_neurons))  \n",
    "model.add(Activation(\"linear\"))  \n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\") \n",
    "print \"Model compiled.\"\n",
    "\n",
    "# and now train the model. \n",
    "model.fit(X_train, y_train, batch_size=30, nb_epoch=200, validation_split=0.1)  \n",
    "predicted = model.predict(X_test)  \n",
    "print np.sqrt(((predicted - y_test) ** 2).mean(axis=0)).mean()  # Printing RMSE \n",
    "\n",
    "@joetigger\n",
    "joetigger commented on Nov 20, 2015\n",
    "\n",
    "@M-Taha Thanks for the example. According to you, TimeDistributedDense is for saving time/memory. Therefore it should work if I set in_out_neurons to 1. However, according to @EdwardRaff it is for constraining many outputs to use the same function. I'm confused.. Which one is correct?\n",
    "@viveksck\n",
    "viveksck commented on Nov 20, 2015\n",
    "\n",
    "@placebokkk : Thanks for the sample code. I tried it, but it seems that it is not able to even memorize the training data.\n",
    "\n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import TimeDistributedDense, Activation, Dropout  \n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "maxlen = 2\n",
    "\n",
    "batch_size = 1\n",
    "nb_word = 4\n",
    "nb_tag = 2\n",
    "\n",
    "X_train = [[1,2],[1,3]]#two sequences, one is [1,2] and another is [1,3]\n",
    "Y_train = [[[0,1],[1,0]],[[0,1],[1,0]]] #the output should be 3D and one-hot for softmax output with categorical_crossentropy\n",
    "X_test = [[1,2],[1,3]]\n",
    "Y_test = [[[0,1],[1,0]],[[0,1],[1,0]]]\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "Y_train = np.asarray(Y_train, dtype='int32')\n",
    "Y_test = np.asarray(Y_test, dtype='int32')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_word, 128))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(TimeDistributedDense(nb_tag))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=100, show_accuracy=True)\n",
    "res = model.predict_classes(X_test)\n",
    "print('res',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
